{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPfzXDZPL+RaQhM2TbMCuo7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kendall3017/Proyecto-2/blob/main/Caso_2_red_neuronal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Simular un conjunto de datos de interacción en entornos virtuales inteligentes\n",
        "num_students = 1000\n",
        "data = {\n",
        "    'tiempo_estudio': np.random.randint(0, 10, num_students),\n",
        "    'num_tareas_completadas': np.random.randint(0, 5, num_students),\n",
        "    'participacion_foro': np.random.randint(0, 3, num_students),\n",
        "    'recursos_visitados': np.random.randint(0, 20, num_students),\n",
        "    'frecuencia_conexion': np.random.randint(1, 7, num_students),\n",
        "    'tiempo_respuesta_foro': np.random.randint(1, 15, num_students),\n",
        "    'calificacion_final': np.random.randint(0, 100, num_students)\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "X = df[['tiempo_estudio', 'num_tareas_completadas', 'participacion_foro', 'recursos_visitados', 'frecuencia_conexion', 'tiempo_respuesta_foro']]\n",
        "y = df['calificacion_final']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Crear el modelo de red neuronal\n",
        "model = Sequential()\n",
        "model.add(Dense(64, input_dim=6, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# Compilar el modelo\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n",
        "\n",
        "# Entrenar el modelo\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32)\n",
        "\n",
        "# Evaluar el modelo\n",
        "_, mae = model.evaluate(X_test, y_test)\n",
        "print('Error medio absoluto:', mae)\n",
        "\n",
        "# Hacer predicciones\n",
        "predicciones = model.predict(X_test)\n",
        "print('Predicciones:', predicciones)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lj0mrvhgWcjr",
        "outputId": "a09afd50-4f84-4043-caa6-b34c6ef28138"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 2889.7043 - mae: 45.6669\n",
            "Epoch 2/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2093.9321 - mae: 38.0482\n",
            "Epoch 3/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1055.4888 - mae: 26.9459\n",
            "Epoch 4/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1101.6598 - mae: 27.4570\n",
            "Epoch 5/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 979.5589 - mae: 25.9099\n",
            "Epoch 6/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 984.5017 - mae: 26.2083 \n",
            "Epoch 7/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 984.8767 - mae: 25.7239\n",
            "Epoch 8/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1011.3829 - mae: 26.7849\n",
            "Epoch 9/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1038.6060 - mae: 26.8375\n",
            "Epoch 10/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 993.4067 - mae: 26.6338 \n",
            "Epoch 11/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 966.2516 - mae: 26.2465\n",
            "Epoch 12/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 1007.1699 - mae: 27.1502\n",
            "Epoch 13/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1030.7737 - mae: 27.1015\n",
            "Epoch 14/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 959.4496 - mae: 26.0008\n",
            "Epoch 15/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 994.2374 - mae: 26.7188\n",
            "Epoch 16/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 909.4996 - mae: 25.3247\n",
            "Epoch 17/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 958.1281 - mae: 26.0340\n",
            "Epoch 18/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1023.2817 - mae: 27.1297\n",
            "Epoch 19/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 958.4979 - mae: 26.2709  \n",
            "Epoch 20/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 965.3893 - mae: 26.1298\n",
            "Epoch 21/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 946.7750 - mae: 26.2808\n",
            "Epoch 22/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 946.8702 - mae: 26.2063  \n",
            "Epoch 23/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 929.7538 - mae: 25.6539\n",
            "Epoch 24/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 948.4595 - mae: 26.1080\n",
            "Epoch 25/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 993.1751 - mae: 26.6854\n",
            "Epoch 26/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 952.5557 - mae: 26.0496\n",
            "Epoch 27/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 887.6863 - mae: 25.5261\n",
            "Epoch 28/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 895.0258 - mae: 25.5254\n",
            "Epoch 29/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1019.8585 - mae: 27.0467\n",
            "Epoch 30/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 842.9570 - mae: 24.7652\n",
            "Epoch 31/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 944.1008 - mae: 26.2985\n",
            "Epoch 32/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 947.3315 - mae: 25.5732\n",
            "Epoch 33/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 930.0370 - mae: 25.7444  \n",
            "Epoch 34/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 875.4988 - mae: 24.8452 \n",
            "Epoch 35/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 896.0392 - mae: 25.3127 \n",
            "Epoch 36/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 940.6875 - mae: 25.9455 \n",
            "Epoch 37/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 897.6428 - mae: 25.3389 \n",
            "Epoch 38/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 825.6506 - mae: 24.3494\n",
            "Epoch 39/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 912.8473 - mae: 25.4907\n",
            "Epoch 40/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 931.3497 - mae: 26.0849\n",
            "Epoch 41/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 914.4977 - mae: 25.4401\n",
            "Epoch 42/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 964.8901 - mae: 26.5486\n",
            "Epoch 43/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 931.2476 - mae: 26.0834\n",
            "Epoch 44/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 891.5374 - mae: 24.9104\n",
            "Epoch 45/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 874.2147 - mae: 25.1444\n",
            "Epoch 46/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 915.4554 - mae: 25.7682\n",
            "Epoch 47/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 893.7690 - mae: 25.7041\n",
            "Epoch 48/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1013.3276 - mae: 27.2280\n",
            "Epoch 49/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 961.8841 - mae: 26.3494 \n",
            "Epoch 50/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 911.0012 - mae: 25.9474\n",
            "Epoch 51/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 885.6653 - mae: 25.4953\n",
            "Epoch 52/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 920.0897 - mae: 25.5937\n",
            "Epoch 53/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 883.1279 - mae: 25.2373\n",
            "Epoch 54/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 885.4985 - mae: 25.2811\n",
            "Epoch 55/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 956.7739 - mae: 26.4216 \n",
            "Epoch 56/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 988.8121 - mae: 26.8338\n",
            "Epoch 57/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 910.5545 - mae: 25.4611\n",
            "Epoch 58/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 926.6872 - mae: 25.6609  \n",
            "Epoch 59/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 906.3611 - mae: 25.6132\n",
            "Epoch 60/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 930.3976 - mae: 25.9570\n",
            "Epoch 61/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 984.4693 - mae: 26.6375\n",
            "Epoch 62/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 882.2567 - mae: 25.1488\n",
            "Epoch 63/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 884.2184 - mae: 25.3998 \n",
            "Epoch 64/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 899.7327 - mae: 25.5968\n",
            "Epoch 65/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 905.3022 - mae: 25.2652\n",
            "Epoch 66/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 893.9360 - mae: 25.8835 \n",
            "Epoch 67/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 905.8231 - mae: 25.7564\n",
            "Epoch 68/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 886.1434 - mae: 25.3238  \n",
            "Epoch 69/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 883.5391 - mae: 25.0569 \n",
            "Epoch 70/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 913.7198 - mae: 25.9731\n",
            "Epoch 71/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 873.5409 - mae: 25.1018 \n",
            "Epoch 72/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 883.5105 - mae: 25.0460 \n",
            "Epoch 73/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 888.9380 - mae: 25.5342 \n",
            "Epoch 74/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 914.9023 - mae: 25.6416\n",
            "Epoch 75/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 891.9038 - mae: 25.2884 \n",
            "Epoch 76/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 839.5768 - mae: 24.4006\n",
            "Epoch 77/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 903.2877 - mae: 25.7630  \n",
            "Epoch 78/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 862.3215 - mae: 24.9978 \n",
            "Epoch 79/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 906.2269 - mae: 25.6665\n",
            "Epoch 80/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 854.4032 - mae: 24.8717  \n",
            "Epoch 81/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 875.1840 - mae: 24.7835\n",
            "Epoch 82/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 913.1027 - mae: 25.9954\n",
            "Epoch 83/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 910.9889 - mae: 26.2412  \n",
            "Epoch 84/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 867.3668 - mae: 25.1716\n",
            "Epoch 85/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 859.4012 - mae: 25.1673 \n",
            "Epoch 86/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 876.1353 - mae: 25.1190 \n",
            "Epoch 87/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 871.0976 - mae: 25.2395\n",
            "Epoch 88/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 820.6996 - mae: 24.3516\n",
            "Epoch 89/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 872.8648 - mae: 25.2409 \n",
            "Epoch 90/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 884.9399 - mae: 25.5027 \n",
            "Epoch 91/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 900.6971 - mae: 25.6672\n",
            "Epoch 92/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 875.6656 - mae: 25.0230\n",
            "Epoch 93/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 905.9778 - mae: 25.9102\n",
            "Epoch 94/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 864.0588 - mae: 24.9487\n",
            "Epoch 95/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 847.8622 - mae: 24.6470\n",
            "Epoch 96/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 885.5597 - mae: 25.2788 \n",
            "Epoch 97/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 874.6168 - mae: 25.2933\n",
            "Epoch 98/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 897.4703 - mae: 25.5807  \n",
            "Epoch 99/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 854.3073 - mae: 24.7638\n",
            "Epoch 100/100\n",
            "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 859.9338 - mae: 24.8880\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 907.0870 - mae: 25.4921  \n",
            "Error medio absoluto: 25.538087844848633\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n",
            "Predicciones: [[38.14431 ]\n",
            " [36.89395 ]\n",
            " [41.95523 ]\n",
            " [34.45102 ]\n",
            " [50.138344]\n",
            " [35.048874]\n",
            " [39.2753  ]\n",
            " [40.845245]\n",
            " [43.006153]\n",
            " [38.13015 ]\n",
            " [39.251255]\n",
            " [46.04253 ]\n",
            " [36.882565]\n",
            " [32.398426]\n",
            " [34.49952 ]\n",
            " [35.999157]\n",
            " [37.870674]\n",
            " [29.402435]\n",
            " [33.6993  ]\n",
            " [42.62292 ]\n",
            " [41.431458]\n",
            " [32.066967]\n",
            " [43.569733]\n",
            " [40.2337  ]\n",
            " [36.20841 ]\n",
            " [39.61503 ]\n",
            " [40.46591 ]\n",
            " [37.116814]\n",
            " [35.788113]\n",
            " [35.838642]\n",
            " [44.356316]\n",
            " [30.708931]\n",
            " [35.33985 ]\n",
            " [42.043655]\n",
            " [38.960705]\n",
            " [28.985294]\n",
            " [34.58412 ]\n",
            " [43.668495]\n",
            " [40.4376  ]\n",
            " [44.8132  ]\n",
            " [40.492523]\n",
            " [40.36077 ]\n",
            " [33.523212]\n",
            " [44.542297]\n",
            " [36.274483]\n",
            " [39.745655]\n",
            " [39.678406]\n",
            " [31.160988]\n",
            " [32.528458]\n",
            " [32.185425]\n",
            " [38.089977]\n",
            " [38.77115 ]\n",
            " [37.691387]\n",
            " [29.602297]\n",
            " [32.11363 ]\n",
            " [26.306904]\n",
            " [20.959026]\n",
            " [35.537685]\n",
            " [36.110783]\n",
            " [39.794563]\n",
            " [42.1728  ]\n",
            " [38.23298 ]\n",
            " [38.831207]\n",
            " [31.676912]\n",
            " [31.981113]\n",
            " [34.3507  ]\n",
            " [40.656616]\n",
            " [40.536175]\n",
            " [43.23974 ]\n",
            " [30.132774]\n",
            " [37.46066 ]\n",
            " [40.51774 ]\n",
            " [42.660873]\n",
            " [45.54145 ]\n",
            " [37.428173]\n",
            " [45.6718  ]\n",
            " [39.479942]\n",
            " [28.412533]\n",
            " [44.10115 ]\n",
            " [40.60378 ]\n",
            " [39.2456  ]\n",
            " [30.39737 ]\n",
            " [41.135155]\n",
            " [40.455364]\n",
            " [38.267525]\n",
            " [37.791985]\n",
            " [42.347893]\n",
            " [40.843967]\n",
            " [42.08414 ]\n",
            " [33.96404 ]\n",
            " [29.564072]\n",
            " [38.728504]\n",
            " [40.345066]\n",
            " [40.119156]\n",
            " [38.986877]\n",
            " [37.77688 ]\n",
            " [42.59562 ]\n",
            " [35.375313]\n",
            " [32.485603]\n",
            " [35.336   ]\n",
            " [38.20627 ]\n",
            " [34.856792]\n",
            " [34.383957]\n",
            " [42.653385]\n",
            " [34.21866 ]\n",
            " [28.238224]\n",
            " [34.78927 ]\n",
            " [43.563194]\n",
            " [32.994278]\n",
            " [31.788591]\n",
            " [40.445816]\n",
            " [27.870773]\n",
            " [45.8824  ]\n",
            " [41.36755 ]\n",
            " [39.948204]\n",
            " [37.985588]\n",
            " [36.27649 ]\n",
            " [47.50096 ]\n",
            " [39.048332]\n",
            " [36.129467]\n",
            " [40.009274]\n",
            " [41.18242 ]\n",
            " [43.155083]\n",
            " [40.464016]\n",
            " [44.058178]\n",
            " [43.363323]\n",
            " [40.008644]\n",
            " [40.86112 ]\n",
            " [37.453697]\n",
            " [38.824512]\n",
            " [42.21248 ]\n",
            " [40.220627]\n",
            " [29.382923]\n",
            " [37.90696 ]\n",
            " [53.310493]\n",
            " [35.194027]\n",
            " [40.089684]\n",
            " [34.009636]\n",
            " [36.013298]\n",
            " [46.638172]\n",
            " [35.68762 ]\n",
            " [40.76759 ]\n",
            " [34.476364]\n",
            " [39.54251 ]\n",
            " [26.856308]\n",
            " [49.2681  ]\n",
            " [40.851265]\n",
            " [35.664597]\n",
            " [38.662037]\n",
            " [42.410187]\n",
            " [33.62406 ]\n",
            " [40.362133]\n",
            " [39.738102]\n",
            " [39.21554 ]\n",
            " [36.320366]\n",
            " [34.433834]\n",
            " [46.512753]\n",
            " [42.875584]\n",
            " [40.430595]\n",
            " [33.178513]\n",
            " [36.08663 ]\n",
            " [29.794832]\n",
            " [39.9224  ]\n",
            " [43.683567]\n",
            " [46.758904]\n",
            " [34.69227 ]\n",
            " [33.92273 ]\n",
            " [42.990494]\n",
            " [44.324768]\n",
            " [44.43991 ]\n",
            " [37.127968]\n",
            " [41.222286]\n",
            " [35.897087]\n",
            " [37.934   ]\n",
            " [46.66179 ]\n",
            " [38.988358]\n",
            " [33.375263]\n",
            " [41.579865]\n",
            " [37.865025]\n",
            " [43.132423]\n",
            " [31.683207]\n",
            " [37.636417]\n",
            " [41.341953]\n",
            " [34.71979 ]\n",
            " [35.35583 ]\n",
            " [45.12161 ]\n",
            " [44.918224]\n",
            " [31.442476]\n",
            " [32.299095]\n",
            " [34.182274]\n",
            " [29.571547]\n",
            " [43.45548 ]\n",
            " [39.014877]\n",
            " [40.357666]\n",
            " [33.45971 ]\n",
            " [42.044884]\n",
            " [34.746292]\n",
            " [40.93324 ]\n",
            " [35.46347 ]\n",
            " [42.88355 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Análisis Crítico:\n",
        "# Evaluar la efectividad del modelo en la personalización de la experiencia educativa.\n",
        "# Discutir las implicaciones éticas y de privacidad relacionadas con el modelado del comportamiento de los estudiantes.\n",
        "\n",
        "## Análisis Crítico del Modelo de Personalización Educativa\n",
        "\n",
        "El código presentado desarrolla un modelo de aprendizaje automático con una red neuronal para predecir la calificación final de los estudiantes en función de su interacción en un entorno virtual inteligente. Si bien el modelo es un primer paso hacia la personalización de la experiencia educativa, es crucial analizar su efectividad, limitaciones y las implicaciones éticas y de privacidad que surgen de su uso.\n",
        "\n",
        "**Efectividad en la Personalización:**\n",
        "\n",
        "* **Potencial:** El modelo tiene potencial para personalizar la experiencia educativa al identificar patrones en el comportamiento de los estudiantes. Por ejemplo, se podría usar para detectar estudiantes con dificultades, ofrecer recursos adicionales o adaptar el ritmo de aprendizaje.\n",
        "* **Limitaciones:** La efectividad del modelo depende de la calidad y cantidad de datos utilizados, así como de la capacidad del modelo para capturar las complejidades del proceso de aprendizaje.\n",
        "* **Precisión:** El modelo actual, con su estructura simple y datos simulados, puede no tener la suficiente precisión para brindar una personalización efectiva. La evaluación del error medio absoluto (MAE) es un punto de partida para evaluar su precisión, pero se necesita un análisis más profundo para determinar si el modelo puede predecir las calificaciones de forma confiable.\n",
        "* **Contexto:** El modelo no considera variables importantes como el nivel de conocimiento previo de los estudiantes, el estilo de aprendizaje, las preferencias o el contexto sociocultural. La incorporación de estas variables es fundamental para una personalización efectiva.\n",
        "\n",
        "**Implicaciones Éticas y de Privacidad:**\n",
        "\n",
        "* **Sesgos:** Los modelos de aprendizaje automático pueden inherentemente reflejar sesgos presentes en los datos. Si los datos de entrenamiento son sesgados, el modelo puede perpetuar desigualdades en el acceso a la educación. Es fundamental asegurar la equidad y la justicia en el uso del modelo.\n",
        "* **Privacidad:** La recopilación y el análisis de datos de interacción de los estudiantes generan preocupaciones sobre la privacidad. Es crucial garantizar que los datos se recopilen y utilicen de forma ética y responsable, respetando la privacidad de los estudiantes y siguiendo los protocolos de protección de datos.\n",
        "* **Transparencia:** La transparencia en el funcionamiento del modelo es fundamental para asegurar la confianza de los usuarios. Los estudiantes y los educadores deben poder entender cómo se utilizan sus datos y cómo influyen en la personalización de la experiencia educativa.\n",
        "* **Control:** Los estudiantes deben tener control sobre sus datos y la forma en que se utilizan. Deben tener la posibilidad de acceder a su información, corregirla y eliminarla si lo desean.\n",
        "\n",
        "**Conclusión:**\n",
        "\n",
        "El modelo desarrollado tiene potencial para la personalización de la experiencia educativa, pero necesita ser evaluado cuidadosamente en cuanto a su efectividad y precisión. Es fundamental abordar las implicaciones éticas y de privacidad asociadas con el modelado del comportamiento de los estudiantes. Se deben desarrollar políticas y protocolos que garanticen la transparencia, la equidad, la privacidad y el control de los estudiantes en la utilización de estos modelos. Además, es crucial integrar las aportaciones de educadores y expertos en didáctica para asegurar que la personalización sea significativa y beneficie el proceso de aprendizaje de forma integral.\n",
        "\n",
        "**Recomendaciones:**\n",
        "\n",
        "* Mejorar la calidad y cantidad de datos utilizados.\n",
        "* Incorporar variables contextuales importantes para el aprendizaje.\n",
        "* Evaluar el modelo con métricas más robustas y contextuales.\n",
        "* Diseñar un proceso de monitorización y evaluación continua del modelo.\n",
        "* Asegurar la transparencia en el funcionamiento del modelo y la protección de la privacidad de los estudiantes.\n",
        "* Implementar políticas y protocolos que aseguren la equidad y la justicia en el uso del modelo.\n",
        "* Consultar con expertos en didáctica y educadores para optimizar la personalización de la experiencia educativa.\n"
      ],
      "metadata": {
        "id": "gUhYKfowW3ZK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}